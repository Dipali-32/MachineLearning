{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80b602-12e7-4ad7-90a9-cdbf69646e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting image capture every 3 seconds. Press 'q' to quit.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160924.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160929.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160933.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160937.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160941.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160945.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160949.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160953.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_160957.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_161001.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n",
      "Image saved to C:/Users/hp/Downloads/Dataset/captured_images\\image_20240820_161005.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Pose classified as: good_pose\n",
      "Pose does not match any good pose images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import pyttsx3\n",
    "\n",
    "# Define paths\n",
    "capture_folder = \"C:/Users/hp/Downloads/Dataset/captured_images\"\n",
    "model_path = \"C:/Users/hp/Downloads/Dataset/pose_classification_model.h5\"\n",
    "good_pose_folder = \"C:/Users/hp/Downloads/Dataset/images/good pose\"\n",
    "\n",
    "# Initialize text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(capture_folder):\n",
    "    os.makedirs(capture_folder)\n",
    "\n",
    "# Load pre-trained model\n",
    "model = load_model(model_path)\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img = cv2.resize(img, (224, 224))  # Resize image to model's input size\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def classify_pose(img):\n",
    "    img = preprocess_img(img)\n",
    "    prediction = model.predict(img)\n",
    "    labels = ['good_pose', 'harmful_pose', 'neutral_pose']\n",
    "    return labels[np.argmax(prediction)]\n",
    "\n",
    "def compare_with_dataset(img):\n",
    "    # Convert the image to a format that can be compared with dataset images\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.array(img) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    for filename in os.listdir(good_pose_folder):\n",
    "        img_path = os.path.join(good_pose_folder, filename)\n",
    "        dataset_img = cv2.imread(img_path)\n",
    "        dataset_img = cv2.resize(dataset_img, (224, 224))\n",
    "        dataset_img = np.array(dataset_img) / 255.0\n",
    "        dataset_img = np.expand_dims(dataset_img, axis=0)\n",
    "        \n",
    "        # Simple comparison (could be improved with a better similarity metric)\n",
    "        if np.allclose(img, dataset_img, atol=0.1):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def speak_message(message):\n",
    "    engine.say(message)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def capture_and_classify():\n",
    "    cap = cv2.VideoCapture(0)  # Open the camera\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access the camera.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting image capture every 3 seconds. Press 'q' to quit.\")\n",
    "    start_time = datetime.now()\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image.\")\n",
    "            break\n",
    "        \n",
    "        cv2.imshow('Captured Image', frame)\n",
    "        \n",
    "        if (datetime.now() - start_time).seconds >= 3:\n",
    "            start_time = datetime.now()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            image_path = os.path.join(capture_folder, f\"image_{timestamp}.jpg\")\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            print(f\"Image saved to {image_path}\")\n",
    "            \n",
    "            # Classify the captured image\n",
    "            pose = classify_pose(frame)\n",
    "            print(f\"Pose classified as: {pose}\")\n",
    "\n",
    "            # Check if image matches dataset images\n",
    "            if compare_with_dataset(frame):\n",
    "                print(\"Pose matches a good pose image.\")\n",
    "                speak_message(\"Good pose detected.\")\n",
    "            else:\n",
    "                print(\"Pose does not match any good pose images.\")\n",
    "                speak_message(\"Warning: Pose does not match any good pose images.\")\n",
    "                \n",
    "            # Display the result image in a window\n",
    "            cv2.imshow('Captured Pose', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "capture_and_classify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f54a4c-1cab-48c0-82fb-9ad7fc433027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
